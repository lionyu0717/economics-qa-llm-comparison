#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
ä¸‹è½½æœ€æ–°çš„å°å‚æ•°æ¨¡å‹åˆ°æœ¬åœ°è¿›è¡Œç¦»çº¿å¾®è°ƒ
"""

import os
import sys
import time
import torch
from pathlib import Path
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer,
    AutoConfig
)
from huggingface_hub import snapshot_download
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelDownloader:
    def __init__(self, base_dir="fine_tuning/models"):
        """
        åˆå§‹åŒ–æ¨¡å‹ä¸‹è½½å™¨
        
        Args:
            base_dir: æ¨¡å‹ä¿å­˜çš„åŸºç¡€ç›®å½•
        """
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # å®šä¹‰è¦ä¸‹è½½çš„æ¨¡å‹
        self.models_to_download = {
            "qwen3-1.7b": {
                "model_name": "Qwen/Qwen3-1.7B", 
                "local_dir": self.base_dir / "qwen3-1.7b",
                "description": "Qwen3 1.7B åŸºç¡€æ¨¡å‹"
            },
            "qwen3-1.7b-instruct": {
                "model_name": "Qwen/Qwen3-1.7B-Instruct",
                "local_dir": self.base_dir / "qwen3-1.7b-instruct", 
                "description": "Qwen3 1.7B æŒ‡ä»¤å¾®è°ƒæ¨¡å‹"
            },
            "llama3.2-3b": {
                "model_name": "meta-llama/Llama-3.2-3B",
                "local_dir": self.base_dir / "llama3.2-3b",
                "description": "Llama 3.2 3B åŸºç¡€æ¨¡å‹"
            },
            "llama3.2-3b-instruct": {
                "model_name": "meta-llama/Llama-3.2-3B-Instruct", 
                "local_dir": self.base_dir / "llama3.2-3b-instruct",
                "description": "Llama 3.2 3B æŒ‡ä»¤å¾®è°ƒæ¨¡å‹"
            }
        }
        
    def check_disk_space(self, required_gb=20):
        """
        æ£€æŸ¥ç£ç›˜ç©ºé—´
        
        Args:
            required_gb: éœ€è¦çš„æœ€å°ç£ç›˜ç©ºé—´(GB)
        """
        import shutil
        free_bytes = shutil.disk_usage(self.base_dir).free
        free_gb = free_bytes / (1024**3)
        
        if free_gb < required_gb:
            logger.warning(f"ç£ç›˜å‰©ä½™ç©ºé—´åªæœ‰ {free_gb:.1f}GBï¼Œå»ºè®®è‡³å°‘æœ‰ {required_gb}GB")
            return False
        else:
            logger.info(f"ç£ç›˜å‰©ä½™ç©ºé—´: {free_gb:.1f}GB âœ…")
            return True
    
    def download_model_files(self, model_name, local_dir, description=""):
        """
        ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•
        
        Args:
            model_name: HuggingFaceæ¨¡å‹åç§°
            local_dir: æœ¬åœ°ä¿å­˜ç›®å½•
            description: æ¨¡å‹æè¿°
        """
        logger.info(f"å¼€å§‹ä¸‹è½½ {description}: {model_name}")
        logger.info(f"ä¿å­˜ä½ç½®: {local_dir}")
        
        try:
            # åˆ›å»ºç›®å½•
            local_dir.mkdir(parents=True, exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
            if (local_dir / "config.json").exists():
                logger.info(f"æ¨¡å‹ {model_name} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return True
            
            start_time = time.time()
            
            # ä½¿ç”¨ snapshot_download ä¸‹è½½æ•´ä¸ªæ¨¡å‹ä»“åº“
            logger.info("æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
            snapshot_download(
                repo_id=model_name,
                local_dir=str(local_dir),
                local_dir_use_symlinks=False,  # ä¸ä½¿ç”¨ç¬¦å·é“¾æ¥ï¼Œç›´æ¥å¤åˆ¶æ–‡ä»¶
                resume_download=True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                ignore_patterns=["*.msgpack", "*.h5", "original/*"]  # å¿½ç•¥ä¸éœ€è¦çš„æ–‡ä»¶
            )
            
            # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
            essential_files = ["config.json", "tokenizer.json"]
            for file in essential_files:
                if not (local_dir / file).exists():
                    logger.warning(f"å…³é”®æ–‡ä»¶ {file} ä¸å­˜åœ¨")
            
            end_time = time.time()
            logger.info(f"âœ… {description} ä¸‹è½½å®Œæˆ! è€—æ—¶: {end_time - start_time:.1f}ç§’")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ {model_name} å¤±è´¥: {str(e)}")
            return False
    
    def test_model_loading(self, model_name, local_dir, description=""):
        """
        æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¡®åŠ è½½
        
        Args:
            model_name: æ¨¡å‹åç§°
            local_dir: æœ¬åœ°ç›®å½•
            description: æ¨¡å‹æè¿°
        """
        logger.info(f"æµ‹è¯•åŠ è½½ {description}...")
        
        try:
            # æµ‹è¯•åŠ è½½é…ç½®
            config = AutoConfig.from_pretrained(str(local_dir))
            logger.info(f"é…ç½®åŠ è½½æˆåŠŸ: {config.model_type}")
            
            # æµ‹è¯•åŠ è½½tokenizer
            tokenizer = AutoTokenizer.from_pretrained(str(local_dir))
            logger.info(f"TokenizeråŠ è½½æˆåŠŸ: è¯æ±‡é‡ {tokenizer.vocab_size}")
            
            # æµ‹è¯•ç¼–ç è§£ç 
            test_text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"
            tokens = tokenizer.encode(test_text)
            decoded_text = tokenizer.decode(tokens)
            logger.info(f"ç¼–ç è§£ç æµ‹è¯•æˆåŠŸ: {len(tokens)} tokens")
            
            # æ£€æŸ¥GPUå†…å­˜
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                logger.info(f"GPUå†…å­˜: {gpu_memory:.1f}GB")
                
                # ä¼°ç®—æ˜¯å¦èƒ½åŠ è½½å®Œæ•´æ¨¡å‹
                if "1.7b" in model_name.lower() or "3b" in model_name.lower():
                    logger.info("å°æ¨¡å‹ï¼ŒGPUå†…å­˜åº”è¯¥è¶³å¤ŸåŠ è½½å®Œæ•´æ¨¡å‹")
                else:
                    logger.info("å¤§æ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨é‡åŒ–æˆ–è€…æ¨¡å‹å¹¶è¡Œ")
            
            logger.info(f"âœ… {description} åŠ è½½æµ‹è¯•æˆåŠŸ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ {description} åŠ è½½æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def download_all_models(self):
        """
        ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        """
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°...")
        logger.info(f"ä¿å­˜ä½ç½®: {self.base_dir.absolute()}")
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        if not self.check_disk_space(30):  # éœ€è¦30GBç©ºé—´
            response = input("ç£ç›˜ç©ºé—´å¯èƒ½ä¸è¶³ï¼Œæ˜¯å¦ç»§ç»­? (y/N): ")
            if response.lower() != 'y':
                logger.info("ä¸‹è½½å·²å–æ¶ˆ")
                return
        
        success_count = 0
        total_count = len(self.models_to_download)
        
        for model_key, model_info in self.models_to_download.items():
            logger.info(f"\n{'='*60}")
            logger.info(f"ä¸‹è½½è¿›åº¦: {success_count + 1}/{total_count}")
            
            success = self.download_model_files(
                model_info["model_name"],
                model_info["local_dir"],
                model_info["description"]
            )
            
            if success:
                # æµ‹è¯•æ¨¡å‹åŠ è½½
                test_success = self.test_model_loading(
                    model_info["model_name"],
                    model_info["local_dir"],
                    model_info["description"]
                )
                if test_success:
                    success_count += 1
                    logger.info(f"âœ… {model_info['description']} å®Œå…¨å°±ç»ª!")
                else:
                    logger.warning(f"âš ï¸ {model_info['description']} ä¸‹è½½æˆåŠŸä½†åŠ è½½æµ‹è¯•å¤±è´¥")
            else:
                logger.error(f"âŒ {model_info['description']} ä¸‹è½½å¤±è´¥")
            
            # çŸ­æš‚æš‚åœï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(2)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ ä¸‹è½½å®Œæˆ!")
        logger.info(f"æˆåŠŸ: {success_count}/{total_count}")
        
        if success_count == total_count:
            logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å‹éƒ½å·²æˆåŠŸä¸‹è½½å¹¶éªŒè¯!")
            self.show_model_info()
        else:
            logger.warning(f"âš ï¸ æœ‰ {total_count - success_count} ä¸ªæ¨¡å‹ä¸‹è½½å¤±è´¥")
    
    def show_model_info(self):
        """
        æ˜¾ç¤ºå·²ä¸‹è½½æ¨¡å‹çš„ä¿¡æ¯
        """
        logger.info("\nğŸ“‹ å·²ä¸‹è½½çš„æ¨¡å‹ä¿¡æ¯:")
        logger.info("-" * 80)
        
        for model_key, model_info in self.models_to_download.items():
            local_dir = model_info["local_dir"]
            if local_dir.exists():
                try:
                    config_file = local_dir / "config.json"
                    if config_file.exists():
                        import json
                        with open(config_file, 'r', encoding='utf-8') as f:
                            config = json.load(f)
                        
                        size_mb = sum(f.stat().st_size for f in local_dir.rglob('*') if f.is_file()) / (1024*1024)
                        
                        logger.info(f"ğŸ“ {model_info['description']}")
                        logger.info(f"   è·¯å¾„: {local_dir}")
                        logger.info(f"   æ¨¡å‹ç±»å‹: {config.get('model_type', 'unknown')}")
                        logger.info(f"   å‚æ•°æ•°é‡: {config.get('num_parameters', 'unknown')}")
                        logger.info(f"   æ–‡ä»¶å¤§å°: {size_mb:.1f} MB")
                        logger.info(f"   è¯æ±‡è¡¨å¤§å°: {config.get('vocab_size', 'unknown')}")
                        logger.info("")
                except Exception as e:
                    logger.info(f"ğŸ“ {model_info['description']}: {local_dir} (æ— æ³•è¯»å–è¯¦ç»†ä¿¡æ¯)")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸ¤– æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("å‡†å¤‡ä¸‹è½½ Qwen3-1.7B å’Œ Llama-3.2-3B æ¨¡å‹...")
    print()
    
    downloader = ModelDownloader()
    
    try:
        downloader.download_all_models()
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main() 