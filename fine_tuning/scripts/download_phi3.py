#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½Google Gemma-3-1Bæ¨¡å‹åˆ°æœ¬åœ°
ç”¨äºä¸Qwen3æ¨¡å‹è¿›è¡Œå¯¹æ¯”å¾®è°ƒ
"""

import os
import sys
import time
import torch
from pathlib import Path
from transformers import AutoModelForCausalLM, AutoTokenizer
from huggingface_hub import snapshot_download
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GemmaDownloader:
    def __init__(self, base_dir="fine_tuning/models"):
        """
        åˆå§‹åŒ–Gemma-3-1Bæ¨¡å‹ä¸‹è½½å™¨
        
        Args:
            base_dir: æ¨¡å‹ä¿å­˜çš„åŸºç¡€ç›®å½•
        """
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨Google Gemma 3-1Bï¼Œæ›´é€‚åˆå¯¹æ¯”
        self.model_info = {
            "name": "gemma-3-1b-it", 
            "hf_model_id": "google/gemma-3-1b-it",
            "local_path": self.base_dir / "gemma-3-1b-it"
        }
        
        # é…ç½®HuggingFace token
        self.hf_token = "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"
    
    def check_dependencies(self):
        """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
        try:
            import torch
            import transformers
            import huggingface_hub
            logger.info("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡")
            return True
        except ImportError as e:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
            return False
    
    def check_disk_space(self, required_gb=10):
        """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
        try:
            import shutil
            free_bytes = shutil.disk_usage(self.base_dir.parent).free
            free_gb = free_bytes / (1024**3)
            
            if free_gb >= required_gb:
                logger.info(f"âœ… ç£ç›˜ç©ºé—´å……è¶³: {free_gb:.1f}GB")
                return True
            else:
                logger.error(f"âŒ ç£ç›˜ç©ºé—´ä¸è¶³: {free_gb:.1f}GB (éœ€è¦ {required_gb}GB)")
                return False
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•æ£€æŸ¥ç£ç›˜ç©ºé—´: {e}")
            return True
    
    def download_model(self):
        """ä¸‹è½½æ¨¡å‹"""
        model_info = self.model_info
        
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½ {} æ¨¡å‹".format(model_info["name"]))
        logger.info("ğŸ“ HuggingFace ID: {}".format(model_info["hf_model_id"]))
        
        try:
            if model_info["local_path"].exists():
                logger.info(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_info['local_path']}")
                return True
            
            logger.info("ğŸ“¥ ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
            snapshot_download(
                repo_id=model_info["hf_model_id"],
                local_dir=str(model_info["local_path"]),
                local_dir_use_symlinks=False,
                resume_download=True,
                token=self.hf_token  # ä½¿ç”¨æä¾›çš„token
            )
            
            logger.info("âœ… {} æ¨¡å‹ä¸‹è½½æˆåŠŸ!".format(model_info["name"]))
            logger.info("ğŸ“ ä¿å­˜ä½ç½®: {}".format(model_info["local_path"]))
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def verify_model(self):
        """éªŒè¯ä¸‹è½½çš„æ¨¡å‹"""
        model_info = self.model_info
        
        try:
            logger.info("ğŸ” éªŒè¯æ¨¡å‹æ–‡ä»¶...")
            
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            required_files = ["config.json", "tokenizer.json", "tokenizer_config.json"]
            missing_files = []
            
            for file in required_files:
                if not (model_info["local_path"] / file).exists():
                    missing_files.append(file)
            
            if missing_files:
                logger.error(f"âŒ ç¼ºå°‘å…³é”®æ–‡ä»¶: {missing_files}")
                return False
            
            # å°è¯•åŠ è½½tokenizer
            tokenizer = AutoTokenizer.from_pretrained(str(model_info["local_path"]))
            logger.info("âœ… TokenizeråŠ è½½æˆåŠŸ")
            
            logger.info("âœ… æ¨¡å‹éªŒè¯é€šè¿‡!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            return False
    
    def run(self):
        """è¿è¡Œä¸‹è½½æµç¨‹"""
        logger.info("ğŸ¤– Gemma-3-1Bæ¨¡å‹ä¸‹è½½å™¨")
        logger.info("=" * 50)
        
        # æ£€æŸ¥ä¾èµ–
        if not self.check_dependencies():
            return False
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        if not self.check_disk_space():
            return False
        
        # ä¸‹è½½æ¨¡å‹
        if not self.download_model():
            logger.error("âŒ ä¸‹è½½å¤±è´¥ï¼è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç£ç›˜ç©ºé—´ã€‚")
            return False
        
        # éªŒè¯æ¨¡å‹
        if not self.verify_model():
            logger.error("âŒ æ¨¡å‹éªŒè¯å¤±è´¥ï¼")
            return False
        
        logger.info("")
        logger.info("ğŸ‰ Gemma-3-1Bæ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        logger.info(f"ğŸ“ æ¨¡å‹ä½ç½®: {self.model_info['local_path']}")
        logger.info("âœ¨ ç°åœ¨å¯ä»¥å¼€å§‹å¾®è°ƒäº†!")
        
        return True

if __name__ == "__main__":
    downloader = GemmaDownloader()
    success = downloader.run()
    
    if not success:
        sys.exit(1) 