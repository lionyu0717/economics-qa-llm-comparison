#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½Google Gemma 3-1Bæ¨¡å‹åˆ°æœ¬åœ°
"""

import os
import sys
import time
import torch
from pathlib import Path
from transformers import AutoModelForCausalLM, AutoTokenizer
from huggingface_hub import snapshot_download
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GemmaDownloader:
    def __init__(self, base_dir="fine_tuning/models"):
        """
        åˆå§‹åŒ–Gemmaæ¨¡å‹ä¸‹è½½å™¨
        
        Args:
            base_dir: æ¨¡å‹ä¿å­˜çš„åŸºç¡€ç›®å½•
        """
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”¹ç”¨Microsoft Phi-3.5-miniï¼Œæ›´é€‚åˆæˆ‘ä»¬çš„éœ€æ±‚
        self.model_info = {
            "name": "phi-3.5-mini-instruct", 
            "hf_model_id": "microsoft/Phi-3.5-mini-instruct",
            "local_path": self.base_dir / "phi-3.5-mini-instruct"
        }
        
    def check_requirements(self):
        """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
        try:
            import torch
            import transformers
            from huggingface_hub import snapshot_download
            logger.info("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡")
            return True
        except ImportError as e:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
            return False
    
    def check_disk_space(self, required_gb=10):
        """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
        import shutil
        free_bytes = shutil.disk_usage(self.base_dir).free
        free_gb = free_bytes / (1024**3)
        
        if free_gb < required_gb:
            logger.warning(f"âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³: {free_gb:.1f}GB < {required_gb}GB")
            return False
        
        logger.info(f"âœ… ç£ç›˜ç©ºé—´å……è¶³: {free_gb:.1f}GB")
        return True
    
    def download_model(self):
        """ä¸‹è½½Gemmaæ¨¡å‹"""
        model_info = self.model_info
        
        logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½ {model_info['name']} æ¨¡å‹")
        logger.info(f"ğŸ“ HuggingFace ID: {model_info['hf_model_id']}")
        logger.info(f"ğŸ’¾ æœ¬åœ°è·¯å¾„: {model_info['local_path']}")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if model_info['local_path'].exists():
            logger.info(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_info['local_path']}")
            return True
        
        try:
            start_time = time.time()
            
            # ä¸‹è½½æ•´ä¸ªæ¨¡å‹ä»“åº“
            logger.info("ğŸ“¥ ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
            snapshot_download(
                repo_id=model_info['hf_model_id'],
                local_dir=str(model_info['local_path']),
                local_dir_use_symlinks=False,
                resume_download=True
            )
            
            download_time = time.time() - start_time
            logger.info(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ! è€—æ—¶: {download_time:.1f}ç§’")
            
            # éªŒè¯ä¸‹è½½
            return self.verify_model(model_info['local_path'])
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def verify_model(self, model_path):
        """éªŒè¯æ¨¡å‹å®Œæ•´æ€§"""
        logger.info("ğŸ” éªŒè¯æ¨¡å‹å®Œæ•´æ€§...")
        
        try:
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            required_files = [
                "config.json",
                "tokenizer.json",
                "tokenizer_config.json"
            ]
            
            missing_files = []
            for file in required_files:
                if not (model_path / file).exists():
                    missing_files.append(file)
            
            if missing_files:
                logger.error(f"âŒ ç¼ºå°‘æ–‡ä»¶: {missing_files}")
                return False
            
            # å°è¯•åŠ è½½tokenizer
            logger.info("ğŸ” æµ‹è¯•tokenizeråŠ è½½...")
            tokenizer = AutoTokenizer.from_pretrained(str(model_path), trust_remote_code=True)
            logger.info(f"âœ… TokenizeråŠ è½½æˆåŠŸï¼Œè¯æ±‡é‡: {len(tokenizer)}")
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å¤§å°
            model_files = list(model_path.glob("*.safetensors")) + list(model_path.glob("*.bin"))
            total_size = sum(f.stat().st_size for f in model_files) / (1024**3)
            logger.info(f"ğŸ“Š æ¨¡å‹æ–‡ä»¶æ€»å¤§å°: {total_size:.2f}GB")
            
            logger.info("âœ… æ¨¡å‹éªŒè¯é€šè¿‡!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            return False
    
    def list_downloaded_models(self):
        """åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹"""
        logger.info("ğŸ“ å·²ä¸‹è½½çš„æ¨¡å‹:")
        
        for model_dir in self.base_dir.iterdir():
            if model_dir.is_dir():
                size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file()) / (1024**3)
                logger.info(f"  ğŸ“¦ {model_dir.name}: {size:.2f}GB")
    
    def run_download(self):
        """æ‰§è¡Œå®Œæ•´çš„ä¸‹è½½æµç¨‹"""
        logger.info("ğŸ¤– Gemmaæ¨¡å‹ä¸‹è½½å™¨")
        logger.info("=" * 50)
        
        # æ£€æŸ¥ç¯å¢ƒ
        if not self.check_requirements():
            return False
        
        if not self.check_disk_space():
            logger.warning("ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œä½†ç»§ç»­å°è¯•ä¸‹è½½...")
        
        # ä¸‹è½½æ¨¡å‹
        success = self.download_model()
        
        if success:
            logger.info("\nğŸ‰ Gemmaæ¨¡å‹ä¸‹è½½æˆåŠŸ!")
            self.list_downloaded_models()
        else:
            logger.error("\nâŒ Gemmaæ¨¡å‹ä¸‹è½½å¤±è´¥!")
        
        return success

def main():
    downloader = GemmaDownloader()
    success = downloader.run_download()
    
    if success:
        print("\nâœ… ä¸‹è½½å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨Gemmaæ¨¡å‹è¿›è¡Œå¾®è°ƒäº†ã€‚")
    else:
        print("\nâŒ ä¸‹è½½å¤±è´¥ï¼è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç£ç›˜ç©ºé—´ã€‚")

if __name__ == "__main__":
    main() 